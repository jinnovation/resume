% !TEX TS-program = lualatex
\documentclass[alternative,10pt,compact]{yaac-another-awesome-cv}
\name{Jonathan}{Jin}
\tagline{Machine Learning Infrastructure Engineer}
\socialinfo{
  \website{https://jonathanj.in}{jonathanj.in}
  \email{me@jonathanj.in}
  \linkedin{jinnovation}
  \github{jinnovation}
}

\setleftcolumnlength{1.5cm}

\begin{document}

\makecvheader

\makecvfooter
    {\textsc{\selectlanguage{english}\today}}
    {\textsc{Jonathan Jin}}
    {}

\sectionTitle{Experience}{\faSuitcase}

\begin{experiences}

  \experience
      {Present}
      {Spotify}
      {Senior Machine Learning Software Engineer}
      {New York}
      {03/2021}{

        \begin{itemize}
        \item Working on: centralized, multi-tenant ML orchestration
          infrastructure with Kubernetes and \href{http://kubeflow.org/}{Kubeflow}; and user-facing
          pipeline-authoring SDK based on \href{http://tensorflow.org/tfx/}{TFX}
        \item Implemented standardized, on-by-default resource quotas to
          mitigate risk of noisy neighbor effect in centralized Kubeflow
          clusters
        \item Oversaw comprehensive formalization of SLO-tracking strategy,
          using Terraform to formalize SLOs in
          \href{https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring}{GCP}
          for all clusters in our multi-cluster in reproducible fashion
        \item Spearheaded development of a custom metrics exporter, transforming
          Kubernetes events into actionable Prometheus metrics to address gaps
          in our observability/reliability strategy
        \end{itemize}
      }
      {TensorFlow, TFX, Kubernetes, Kubeflow, GCP, Terraform, Prometheus, gRPC}

  \emptySeparator

  \experience
      {01/2021}
      {NVIDIA}
      {Senior Systems Software Engineer, AI Infrastructure}
      {New York}
      {12/2019}
      {
        \begin{itemize}
        \item Developing solution for “hybrid data/model parallelism” using a
          Ray-based parameter server design and Horovod to enable
          horizontally-scalable multi-task training
        \item Co-delivered a Kubernetes-based scheduling mechanism to enable
          priority access to cluster resources for select use cases, e.g. prep for
          upcoming external demos, via virtual “resource shares”
        \item Authored self-service, reproducible, and traceable workflows to
          generate “miniaturized” production datasets, enabling rapid
          iteration/prototyping of training infrastructure refinements
        \end{itemize}
      }
      {Kubernetes, TensorFlow, Horovod, Ray, gRPC, Bazel, SwiftStack}

  \emptySeparator

  \experience
      {12/2019}
      {Twitter}
      {Machine Learning Software Engineer}
      {New York}
      {08/2018}
      {
        \begin{itemize}
        \item Core contributor to
          \href{https://blog.twitter.com/engineering/en_us/topics/insights/2018/ml-workflows.html}{ML
            Workflows}, Twitter’s Airflow-based platform for productionizing ML
          pipelines
        \item
          Spearheaded initial integration and cross-compatibility of
          \href{http://tensorflow.org/tfx/}{TensorFlow Extended (TFX)} with ML
          Workflows to increase agility of workflow development, iterative
          execution/experimentation, etc.
        \item
          Enabled distributed training of TensorFlow models in Apache Mesos from
          an Airflow pipeline via
          \href{https://blog.twitter.com/engineering/en_us/topics/insights/2018/twittertensorflow.html}{Deepbird},
          Twitter’s TensorFlow-based model training/evaluating/serving framework
        \end{itemize}
      }
      {Apache Airflow, Apache Aurora, TensorFlow}

  \emptySeparator

  \experience
      {07/2018}
      {Uber}
      {Software Engineer}
      {New York}
      {07/2016}
      {
        \begin{itemize}
        \item
          Re-architected time-series metric forecasting pipeline to support
          concurrent batch backfilling; reduced asymptotic burden on underlying
          data store by ~90\%
        \item
          Extended M3-based anomaly detection platform to support multiple
          forecasting models; carried out migration to intercommunicating
          services with zero downtime and full backwards compatibility

        \end{itemize}
      }
      {Go, Java, M3, Apache Thrift, Cassandra}

  \emptySeparator

  \experience
      {07/2016}
      {OkCupid}
      {Software Engineer}
      {New York}
      {07/2015}
      {
        \begin{itemize}
        \item Contributed to backend service development as part of a 10-person
          backend engineering team.
        \item Implemented prototype collaborative filtering functionality for
          matching between prospectively compatible users.
        \end{itemize}

      }
      {C++}
\end{experiences}

\sectionTitle{Skills}{\faTasks}

\begin{keywords}
  \keywordsentry{Programming Languages}
  {
    Python,
    Go,
    Bash,
    C++,
    Java
  }
  \keywordsentry{Machine Learning}
  {
    Kubeflow,
    TensorFlow Extended (TFX),
    TensorFlow,
  }
  \keywordsentry{Distributed Systems}
  {
    Kubernetes,
    gRPC
  }
  \keywordsentry{Infrastructure Tooling}
  {
    Bazel,
    Prometheus,
    Grafana,
    M3,
    Cassandra,
    Apache Airflow,
  }

  \keywordsentry{Cloud Infrastructure}
  {
    Google Cloud Platform (GCP)
  }
\end{keywords}

\sectionTitle{Education}{\faGraduationCap}

\begin{scholarship}
  \scholarshipentry{2015}
  {\textbf{University of Chicago}, B.S. Computer Science, B.A. Economics}
\end{scholarship}

\end{document}
