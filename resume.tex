% !TEX TS-program = lualatex

\documentclass[alternative,10pt,compact]{yaac-another-awesome-cv}

\name{Jonathan}{Jin}
\tagline{Machine Learning Infrastructure Engineer}
\socialinfo{
  \website{https://jonathanj.in}{jonathanj.in}
  \email{me@jonathanj.in}
  \linkedin{jinnovation}
  \github{jinnovation}
}

\renewcommand\user[2]{\color{accentcolor}{\LARGE\textbf{#1 #2}}\color{Black}}

\renewcommand\resumetitle[1]{
  %% \ifundef{\@alternative}{
  %%    \par{
  %%    	 \bigskip\center{\Large \color{accentcolor}\textbf{#1}\color{Black}}\par
  %%    }
  %%    \bigskip
  %% }{
    \large{#1}
  %% }
}

\setleftcolumnlength{1.5cm}
\setlength{\rightcolumnlength}{\dimexpr(\rightcolumnlength-0.5cm)\relax}

\newcommand\experiencewithblurb[8]{
  #1    & \textbf{\accentcolor{#2}} \textsc{#3} \hfill #4   \\*
  #5    & \textit{#6} \\*
        & \begin{minipage}[t]{\rightcolumnlength}
            #7
          \end{minipage}									\\*
        & \footnotesize{\foreach \n in {#8}{\cvtag{\n}}} 	\\
}

\newcommand\sectionHeader[1]{\section{\texorpdfstring{\color{accentcolor}\textsc{#1}}{#1}}}

\newcommand\accentcolor[1]{\color{accentcolor}#1\color{Black}}

\begin{document}

%% cls sets French as the default babel language; we undo that here.
\selectlanguage{english}

\makecvheader

\makecvfooter
    {\textsc{\today}}
    {\textsc{Jonathan Jin}}
    {}

\sectionHeader{Experience}

\begin{experiences}

  \experiencewithblurb
      {Present}
      {Spotify}
      {Senior Machine Learning Software Engineer}
      {New York}
      {03/2021}
      {Member of ML Platform. Working on: centralized, multi-tenant ML
        orchestration infrastructure with Kubernetes and
        \link{http://kubeflow.org/}{Kubeflow}; and user-facing
        pipeline-authoring SDK based on \link{http://tensorflow.org/tfx/}{TFX}.
      }
      {
        \begin{itemize}
          %% TODO: Talk about Ray work
          %% \item Leading a multi-quarter migration of our TFX-based, user-facing
          %%   SDK to TFX's Protobuf-based ``intermediate
          %%   representation''. Implemented design and carried out gradual rollout
          %%   and deprecation strategy of the ``legacy'' pipeline submission
          %%   logic, with zero user-facing impact;
          %% \item Spearheaded, in collaboration with product and engineering
          %%   management, the promotion of our pipeline orchestration
          %%   infrastructure + SDK to general availability, helping to define
          %%   requirements and core tenets;
          %% \item Spearheaded the development of a formal API design philosophy
          %%   and strategy for our user-facing pipeline-authoring SDK, overhauling
          %%   documentation system for full API coverage and formalizing API
          %%   deprecation strategy, optimizing for user clarity and zero ambiguity;
        \item Oversaw comprehensive formalization of SLO-tracking strategy,
          using Terraform to formalize SLOs in
          \link{https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring}{GCP}
          for all clusters in our multi-cluster in reproducible fashion;
        \item Spearheaded development of a custom metrics exporter, transforming
          Kubernetes events into actionable Prometheus metrics to address gaps
          in our observability/reliability strategy.
        \end{itemize}
      }
      {TensorFlow, TFX, Kubernetes, Kubeflow, GCP, Terraform, Prometheus, gRPC, Ray}

  \emptySeparator

  \experiencewithblurb
      {01/2021}
      {NVIDIA}
      {Senior Systems Software Engineer, AI Infrastructure}
      {New York}
      {12/2019}
      {Member of AI Infrastructure. Contributor to
        \link{https://blogs.nvidia.com/blog/2018/09/13/how-maglev-speeds-autonomous-vehicles-to-superhuman-levels-of-safety/}{MagLev},
        NVIDIA’s AI infrastructure for autonomous vehicle development. Also
        contributed to Modulus, the deep learning SDK for autonomous vehicle
        R\&D.}
      {
        \begin{itemize}
        \item Initiated development of solution for ``hybrid data/model
          parallelism'' using a Ray-based parameter server design and Horovod to
          enable horizontally-scalable multi-task training;
        \item Co-delivered a Kubernetes-based scheduling mechanism to enable
          priority access to cluster resources for select use cases, e.g. prep for
          upcoming external demos, via virtual ``resource shares'';
        \end{itemize}
      }
      {Kubernetes, TensorFlow, Horovod, Ray, gRPC, Bazel, SwiftStack}

  \emptySeparator

  \experiencewithblurb
      {12/2019}
      {Twitter}
      {Machine Learning Software Engineer}
      {New York}
      {08/2018}
      {Member of \link{http://cortex.twitter.com}{Cortex}, Twitter's central ML
        platform organization. Worked on: workflow orchestration; experiment
        management/iteration; and overall ML engineering productivity.}
      {
        \begin{itemize}
        \item
          Spearheaded initial integration of
          \link{http://tensorflow.org/tfx/}{TensorFlow Extended (TFX)} with
          \link{https://blog.twitter.com/engineering/en_us/topics/insights/2018/ml-workflows.html}{legacy
            Airflow-based orchestration platform} to increase agility of
          workflow development, iterative execution/experimentation, etc.
        \item
          Enabled distributed training of TensorFlow models in Apache Mesos from
          an Airflow pipeline via
          \link{https://blog.twitter.com/engineering/en_us/topics/insights/2018/twittertensorflow.html}{Deepbird},
          Twitter’s TensorFlow-based model training/evaluating/serving framework
        \end{itemize}
      }
      {Apache Airflow, Apache Aurora, TensorFlow}

  \emptySeparator

  \experiencewithblurb
      {07/2018}
      {Uber}
      {Software Engineer}
      {New York}
      {07/2016}
      {Member of \link{https://eng.uber.com/observability-at-scale/}{Observability Applications}. Worked on forecasting and anomaly detection for time series metrics.}
      {
        \begin{itemize}
        \item
          Re-architected time-series metric forecasting pipeline to support
          concurrent batch backfilling; reduced asymptotic burden on underlying
          data store by ~90\%
        \item
          Extended M3-based anomaly detection platform to support multiple
          forecasting models; carried out migration to intercommunicating
          services with zero downtime and full backwards compatibility

        \end{itemize}
      }
      {Go, Java, M3, Apache Thrift, Cassandra}

  \emptySeparator

  \experiencewithblurb
      {07/2016}
      {OkCupid}
      {Software Engineer}
      {New York}
      {07/2015}
      {Contributed to backend service development as part of a 10-person backend engineering team.}
      {
        \begin{itemize}
        \item Implemented collaborative filtering for matching between
          prospectively compatible users.
        \end{itemize}
      }
      {C++}
\end{experiences}

\sectionHeader{Skills}

\begin{keywords}
  \keywordsentry{Programming Languages}
  {
    Python,
    Go,
    Bash,
    C++,
    Java
  }
  \keywordsentry{Machine Learning}
  {
    Kubeflow,
    TensorFlow Extended (TFX),
    TensorFlow,
    Ray
  }
  \keywordsentry{Distributed Systems}
  {
    Kubernetes,
    gRPC
  }
  \keywordsentry{Infrastructure Tooling}
  {
    Bazel,
    Prometheus,
    Grafana,
    M3,
    Cassandra,
    Apache Airflow
  }

  \keywordsentry{Cloud Infrastructure}
  {
    Google Cloud Platform (GCP),
    Terraform
  }
\end{keywords}

\sectionHeader{Education}

\begin{scholarship}
  \scholarshipentry{2015}{\textbf{University of Chicago}, B.S. Computer Science, B.A. Economics}
\end{scholarship}

\end{document}
